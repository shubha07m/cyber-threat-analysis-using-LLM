{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZssN0mgyBYj",
        "outputId": "e6d33e42-f82c-4184-9fee-51e29d3af535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive and importing library\n",
        "import pandas as pd\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract text from HTML content\n",
        "def extract_text_from_html(url):\n",
        "    response = requests.get(url)\n",
        "    html_content = response.text\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    text = soup.get_text()\n",
        "    return text"
      ],
      "metadata": {
        "id": "Px7YeefcyNGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the URL dictionary from the CSV file\n",
        "url_dict_file = \"/content/drive/My Drive/newtask/url_dict.csv\"\n",
        "url_df = pd.read_csv(url_dict_file)\n",
        "url_dict = dict(zip(url_df['Document Name'], url_df['url']))"
      ],
      "metadata": {
        "id": "kK4x7-YgyWPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intial cleaning of text data\n",
        "cleaned_apt_data = []\n",
        "\n",
        "for name, url in url_dict.items():\n",
        "  print(f\"Processing document: {name}\")  # Informative message\n",
        "  try:\n",
        "    # Extract text from HTML\n",
        "    html_content = extract_text_from_html(url)\n",
        "    html_refined = re.sub(r'\\b\\w{12,}\\b', '', html_content)\n",
        "    md5_refined = re.sub(r\"MD5:\\s*\\w+\", \"MD5:\", html_refined)\n",
        "    cleaned_apt_data.append(md5_refined)\n",
        "  except Exception as e:\n",
        "    print(f\"Error processing document {name}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCzCvLpAyowf",
        "outputId": "6e770339-a0a3-4fbc-f25b-bcf2c3080489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing document: Midnight Blizzard conducts targeted social engineering over Microsoft Teams\n",
            "Processing document: Midnight Blizzard guidance for responders on nation-state attack\n",
            "Processing document: TeamCity intrusion saga  APT29 suspected exploiting CVE-2023-42793\n",
            "Processing document: APT29 targeting German political parties with new WineLoader malware\n",
            "Processing document: APT29 evolving diplomatic phishing campaigns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path to save cleaned data\n",
        "output_file_path = '/content/drive/My Drive/newtask/cleaned_apt_data.txt'\n",
        "\n",
        "# Save the generated cleaned data to a text file\n",
        "with open(output_file_path, \"w\") as file:\n",
        "    # Iterate over each element in the exp_data array\n",
        "  for text_data in cleaned_apt_data:\n",
        "    # Write the text data to the file\n",
        "      file.write(text_data + \"\\n\")"
      ],
      "metadata": {
        "id": "sYKYQ55U0LAc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}